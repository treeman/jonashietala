---toml
title = "Kubernetes"
tags = ["Some tag"]
---

:table-of-content:

<https://github.com/hobby-kube/guide>

# Rancher to manage Kubernetes

![Rancher offers a view of the nodes and their usage, among a bunch of other things.](/images/kubernetes/rancher_nodes.png)

One thing I've been missing with my old homelab setup where I `ssh` to my server and run containers via `docker compose` is a nice dashboard.
As I'm already using [k3s][] and plan on using [Longhorn][], it makes sense to try out [Rancher][] as it's made by the same team.

By complete coincidence there's also a [Jim's Garage][] video about [deploying Rancher][] and an [accompanying readme][] with instructions on how to install it.

## Install helm

I'll install [Rancher][] using [Helm][], so [let's install it][]:

```bash
curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
chmod 700 get_helm.sh
./get_helm.sh
```

```fish-shell
$ helm version
version.BuildInfo{Version:"v3.18.2", GitCommit:"04cad4610054e5d546aa5c5d9c1b1d5cf68ec1f8", GitTreeState:"clean", GoVersion:"go1.24.3"}
```

## Install cert-manager

Next, we'll [install cert-manager][]:

```bash
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.18.0/cert-manager.crds.yaml
helm repo add jetstack https://charts.jetstack.io
helm repo update
helm install cert-manager jetstack/cert-manager \
   --namespace cert-manager \
   --create-namespace \
   --version v1.18.0
```

And verify installation:

```fish-shell
$ kubectl get pods --namespace cert-manager
NAME                                       READY   STATUS    RESTARTS   AGE
cert-manager-788d58b76f-7wws8              1/1     Running   0          2d
cert-manager-cainjector-5f6f659459-znprj   1/1     Running   0          2d
cert-manager-webhook-75d4c8db8b-97djk      1/1     Running   0          2d
```

## Install Rancher

Now we can finally install [Rancher][].
First, the repo:

```bash
helm repo add rancher-latest https://releases.rancher.com/server-charts/latest
```

It's apparently good style to use a namespace:

```bash
kubectl create namespace cattle-system
```

The next step should be to install it, making sure to use the domain you want to use for your homelab:

```bash
helm install rancher rancher-latest/rancher \
   --namespace cattle-system \
   --set hostname=rancher.hietala.xyz \
   --set bootstrapPassword=admin
```

However,
I got a version incompatibility error:

```
Error: INSTALLATION FAILED: chart requires kubeVersion: < 1.33.0-0 which is incompatible with Kubernetes v1.33.1+k3s1
```

This didn't go away even if I used the alpha version of [Rancher][] with `https://releases.rancher.com/server-charts/alpha` or updated [Helm][] to the latest version.

One solution would be to downgrade Kubernetes to an older version...
But that sounds annoying.

I instead
[found a workaround](https://github.com/rancher/rancher/issues/43092#issuecomment-2423135070)
that removes the `kubeVersion` requirement from the [Rancher][] chart and then installs it:

```bash
mkdir tmp
cd tmp
helm fetch rancher-latest/rancher --untar
sed -i "/kubeVersion/d" Chart.yaml
helm install rancher . \
   --namespace cattle-system \
   --set hostname=rancher.hietala.xyz \
   --set bootstrapPassword=admin
```

Yeah, it may explode in your face but it seems to have worked this time.

This can take a while so we can wait and confirm the deployment with:

```bash
kubectl -n cattle-system rollout status deploy/rancher
kubectl -n cattle-system get deploy rancher
```

## Expose Rancher via load balancer

But how do we access [Rancher][]?

```fish-shell
$ kubectl get svc -n cattle-system
NAME                       TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
imperative-api-extension   ClusterIP      10.43.134.212   <none>        6666/TCP         2d
rancher                    ClusterIP      10.43.151.31    <none>        80/TCP,443/TCP   2d
rancher-webhook            ClusterIP      10.43.38.150    <none>        443/TCP          2d
```

There's no external IP we can access?

Like we did [with nginx last time](#Test-by-deploying-nginx) we need to expose the service via the load balancer:

```bash
kubectl expose deployment rancher --name=rancher-lb --port=443 --type=LoadBalancer -n cattle-system
```

This time we exposed a new service on port `443` so it secures the connection and it also generates a self-signed certificate for us.

See:

{hl=5}
```fish-shell
$ kubectl get svc -n cattle-system
NAME                       TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
imperative-api-extension   ClusterIP      10.43.134.212   <none>        6666/TCP         2d
rancher                    ClusterIP      10.43.151.31    <none>        80/TCP,443/TCP   2d
rancher-lb                 LoadBalancer   10.43.118.11    10.1.2.101    443:31413/TCP    2d
rancher-webhook            ClusterIP      10.43.38.150    <none>        443/TCP          2d
```

Excellent.


# Setting up Traefik

Also try to move some other services?

# GitOps with Fleet

# Moving my home automation services to Kubernetes

- Postgres
- haex
- Home Assistant
- mqtt
- zigbee2mqtt
- Music Assistant

# A Proxmox k3s node with GPU passthrough

- Jellyfin

Might consider an extra Longhorn node too.

{% Should we also have the Zigbee dongle on this node or connected to a Pi? %}

# HA Postgres

<https://ryan-schachte.com/blog/ha_postgres_zolando/>
<https://dev.to/dm8ry/how-to-deploy-a-high-availability-ha-postgres-cluster-in-kubernetes-79>

# Setup services

## Other services

- audiobookshelf
- Grafana
- influxdb
- unifi controller
- freshrss
- reddit-top-rss
- actualbudget
- newt (expose to pangolin)
- tailscale
- traefik / ingress controller



With our first Kubernetes node up and running we can add kube-vip as a service on the cluster itself, which will provide the virtual IP address for cluster itself. This is neat as we don’t have to have any extra hardware or software “in front” of the cluster to act as an entry point.

This way the cluster can use a single IP address even when some of the nodes shuts down. It feels a bit magical to me but people smarter than me have found a way.

First create the RBAC settings (permissions):

kubectl apply -f https://kube-vip.io/manifests/rbac.yaml

We need need to create a beautiful yaml file at /var

[deploying Rancher]: https://www.youtube.com/watch?v=hT2_O2Yd_wE
[accompanying readme]: https://github.com/JamesTurland/JimsGarage/tree/main/Kubernetes/Rancher-Deployment
[Longhorn]: https://longhorn.io/
[Rancher]: https://ranchermanager.docs.rancher.com/v2.6
[let's install it]: https://helm.sh/docs/intro/install/
[Helm]: https://helm.sh/
[install cert-manager]: https://cert-manager.io/docs/installation/helm/
[iscsi_tcp module]: https://askubuntu.com/questions/1373309/missing-iscsi-tcp-kernel-module-in-ubuntu-21-10-for-raspberry-pi-arm64
[k3s]: https://minikube.sigs.k8s.io/docs/
[Jim's Garage]: https://www.youtube.com/@Jims-Garage
[example of how to generate it]: https://kube-vip.io/docs/installation/daemonset/#arp-example-for-daemonset
